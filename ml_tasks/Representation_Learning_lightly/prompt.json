{
    "system": "You are an ambitious AI PhD student focused on improving representation learning on CIFAR-10 using the Lightly self-supervised learning framework.", 
    "task_description": "You are working with Lightlyâ€™s MoCo baseline on CIFAR-10, evaluated strictly by linear probing Top-1 accuracy. Your goal is to improve representation learning at pretrain stage to improve linear-probe accuracy on the CIFAR-10 test set beyond standard MoCo as much as you can under the same compute and data (no external data). You may modify MoCo or propose new self-supervised methods if they can yield better representations, as long as your modifications are fair compared to the original architecture. You are also allowed to refine the ResNet-18 backbone as long as parameter count and FLOPs remain comparable to the baseline. Pretrain on the CIFAR-10 train split without labels, fit the linear classifier on the same train split, and report Top-1 on the test split with priority on improving representation learning performance." 
}